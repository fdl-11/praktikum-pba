{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f191a3ba",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9254920",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.5.3-cp310-cp310-win_amd64.whl (12.2 MB)\n",
      "     --------------------------------------- 12.2/12.2 MB 14.2 MB/s eta 0:00:00\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp310-cp310-win_amd64.whl (94 kB)\n",
      "     ---------------------------------------- 94.7/94.7 kB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy) (22.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Downloading pydantic-1.10.9-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 9.6 MB/s eta 0:00:00\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp310-cp310-win_amd64.whl (29 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp310-cp310-win_amd64.whl (18 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting thinc<8.2.0,>=8.1.8\n",
      "  Downloading thinc-8.1.10-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 8.5 MB/s eta 0:00:00\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.6-cp310-cp310-win_amd64.whl (480 kB)\n",
      "     -------------------------------------- 480.9/480.9 kB 6.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     -------------------------------------- 181.6/181.6 kB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Collecting pathy>=0.10.0\n",
      "  Downloading pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "     ---------------------------------------- 48.9/48.9 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp310-cp310-win_amd64.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 8.0 MB/s eta 0:00:00\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, pydantic, murmurhash, langcodes, catalogue, blis, typer, srsly, preshed, pathy, confection, thinc, spacy\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 confection-0.0.4 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.1 preshed-3.0.8 pydantic-1.10.9 spacy-3.5.3 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 thinc-8.1.10 typer-0.7.0 wasabi-1.1.2\n"
     ]
    }
   ],
   "source": [
    "#INSTAL SPACY LIBRARY\n",
    "\n",
    "!pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dbc3a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     --------------------------------------- 12.8/12.8 MB 56.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (65.6.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.9)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\praktikan-06\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.5.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "#INSTAL LIBRARY EN CORE WEB SM\n",
    "\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea7c6544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependencies\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "622f63ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definisikan teks\n",
    "\n",
    "text = \"\"\" There are broadly two types of extractive summarization tasks depending on what the summarization the first is generic summarization, which focuses on obtaning a generic summary or abstract of the collection (whethere documments, or sets of images, or videos, news stories stc.). The second is query relevant summarizion, sometimes called query-based summarizion, which summarizes objects specific to query. Summarization system are able create both query relevant text summarizes and generic machine-generated summaries depending on what the user needs. An example of summarization problem is document summarization wich attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represent the latest news as a summary. Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a large set of images. A summary in this context is useful to show the most representative images of results in image collection exploration system. Video summarization is a related domain, where one the iystem automatically creates a treailler of a long video. this aslo has application in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarry, in surveillance videos, one would wnat to extract important and suspicious activity, while ignoring all the boring and redundant frames captures. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "03597706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['least',\n",
       " 'whereby',\n",
       " 'yourselves',\n",
       " 'side',\n",
       " 'none',\n",
       " 'should',\n",
       " 'give',\n",
       " 'does',\n",
       " 'seem',\n",
       " 'did',\n",
       " 'front',\n",
       " 'while',\n",
       " 'under',\n",
       " 'whence',\n",
       " 're',\n",
       " 'do',\n",
       " 'where',\n",
       " 'amount',\n",
       " 'various',\n",
       " 'beforehand',\n",
       " 'doing',\n",
       " 'became',\n",
       " 'more',\n",
       " 'because',\n",
       " '’ll',\n",
       " 'namely',\n",
       " 'about',\n",
       " 'her',\n",
       " 'what',\n",
       " 'anyway',\n",
       " 'you',\n",
       " 'him',\n",
       " 'last',\n",
       " 'the',\n",
       " 'else',\n",
       " 'everyone',\n",
       " 'per',\n",
       " 'two',\n",
       " 'themselves',\n",
       " 'since',\n",
       " \"'ll\",\n",
       " 'nobody',\n",
       " 'she',\n",
       " 'being',\n",
       " 'whither',\n",
       " 'anywhere',\n",
       " 'get',\n",
       " 'almost',\n",
       " 'cannot',\n",
       " 'here',\n",
       " 'amongst',\n",
       " 'latterly',\n",
       " '’d',\n",
       " 'alone',\n",
       " 'regarding',\n",
       " 'few',\n",
       " 'becomes',\n",
       " 'together',\n",
       " 'even',\n",
       " 'sometimes',\n",
       " 'further',\n",
       " 'over',\n",
       " 'myself',\n",
       " 'noone',\n",
       " 'something',\n",
       " 'an',\n",
       " 'nor',\n",
       " 'elsewhere',\n",
       " '’s',\n",
       " 'bottom',\n",
       " '‘ve',\n",
       " 'which',\n",
       " 'show',\n",
       " 'herself',\n",
       " 'whether',\n",
       " 'out',\n",
       " 'i',\n",
       " 'until',\n",
       " 'top',\n",
       " 'hereby',\n",
       " 'through',\n",
       " 'otherwise',\n",
       " 'serious',\n",
       " 'due',\n",
       " 'however',\n",
       " \"'s\",\n",
       " 'across',\n",
       " 'much',\n",
       " 'fifty',\n",
       " 'thereupon',\n",
       " 'it',\n",
       " 'just',\n",
       " 'ours',\n",
       " 'whoever',\n",
       " 'have',\n",
       " 'they',\n",
       " 'but',\n",
       " '‘s',\n",
       " 'anyone',\n",
       " 'other',\n",
       " 'same',\n",
       " 'except',\n",
       " 'not',\n",
       " 'into',\n",
       " 'may',\n",
       " 'along',\n",
       " 'everything',\n",
       " 'move',\n",
       " 'on',\n",
       " 'were',\n",
       " 'are',\n",
       " 'only',\n",
       " 'by',\n",
       " 'via',\n",
       " 'from',\n",
       " 'these',\n",
       " 'moreover',\n",
       " \"'d\",\n",
       " 'hereupon',\n",
       " 'too',\n",
       " 'enough',\n",
       " 'mostly',\n",
       " 'off',\n",
       " 'nevertheless',\n",
       " 'ca',\n",
       " 'among',\n",
       " 'keep',\n",
       " 'when',\n",
       " 'might',\n",
       " 'every',\n",
       " 'former',\n",
       " 'somehow',\n",
       " 'mine',\n",
       " 'of',\n",
       " 'must',\n",
       " 'although',\n",
       " 'own',\n",
       " 'himself',\n",
       " 'itself',\n",
       " 'after',\n",
       " 'thus',\n",
       " '‘re',\n",
       " 'four',\n",
       " 'them',\n",
       " 'if',\n",
       " '‘m',\n",
       " 'throughout',\n",
       " 'am',\n",
       " 'upon',\n",
       " 'wherein',\n",
       " 'also',\n",
       " 'nothing',\n",
       " 'thereby',\n",
       " 'we',\n",
       " \"n't\",\n",
       " 'sometime',\n",
       " '‘d',\n",
       " 'afterwards',\n",
       " 'whose',\n",
       " 'take',\n",
       " 'quite',\n",
       " 'anything',\n",
       " 'full',\n",
       " 'another',\n",
       " 'meanwhile',\n",
       " 'thru',\n",
       " 'someone',\n",
       " 'can',\n",
       " 'twelve',\n",
       " 'ten',\n",
       " 'had',\n",
       " 'your',\n",
       " 'whereafter',\n",
       " 'everywhere',\n",
       " 'very',\n",
       " 'thereafter',\n",
       " 'all',\n",
       " 'put',\n",
       " 'five',\n",
       " 'whom',\n",
       " 'become',\n",
       " '‘ll',\n",
       " 'than',\n",
       " 'others',\n",
       " 'third',\n",
       " 'was',\n",
       " 'whereupon',\n",
       " 'name',\n",
       " 'my',\n",
       " 'onto',\n",
       " 'below',\n",
       " 'their',\n",
       " 'hers',\n",
       " 'call',\n",
       " 'whenever',\n",
       " 'most',\n",
       " 'who',\n",
       " 'our',\n",
       " 'us',\n",
       " 'done',\n",
       " 'nowhere',\n",
       " 'beside',\n",
       " 'sixty',\n",
       " 'anyhow',\n",
       " 'around',\n",
       " 'then',\n",
       " \"'ve\",\n",
       " 'fifteen',\n",
       " 'often',\n",
       " 'this',\n",
       " 'hereafter',\n",
       " 'herein',\n",
       " 'still',\n",
       " 'between',\n",
       " 'becoming',\n",
       " 'n‘t',\n",
       " 'his',\n",
       " 'in',\n",
       " 'its',\n",
       " 'always',\n",
       " 'part',\n",
       " 'many',\n",
       " 'thence',\n",
       " 'again',\n",
       " 'how',\n",
       " 'so',\n",
       " 'yours',\n",
       " '’ve',\n",
       " 'above',\n",
       " 'whereas',\n",
       " 'towards',\n",
       " 'against',\n",
       " \"'m\",\n",
       " 'up',\n",
       " 'for',\n",
       " 'besides',\n",
       " 'before',\n",
       " 'or',\n",
       " 'seeming',\n",
       " 'six',\n",
       " 'next',\n",
       " 'rather',\n",
       " 'ever',\n",
       " 'never',\n",
       " 'at',\n",
       " 'is',\n",
       " 'several',\n",
       " 'such',\n",
       " 'perhaps',\n",
       " 'as',\n",
       " 'seems',\n",
       " 'hence',\n",
       " 'that',\n",
       " 'with',\n",
       " 'really',\n",
       " 'neither',\n",
       " 'one',\n",
       " 'empty',\n",
       " 'made',\n",
       " 'been',\n",
       " 'wherever',\n",
       " 'why',\n",
       " 'formerly',\n",
       " 'those',\n",
       " 'beyond',\n",
       " 'to',\n",
       " 'three',\n",
       " 'using',\n",
       " 'will',\n",
       " 'behind',\n",
       " 'make',\n",
       " 'without',\n",
       " 'well',\n",
       " 'each',\n",
       " \"'re\",\n",
       " 'therefore',\n",
       " '’re',\n",
       " 'a',\n",
       " 'go',\n",
       " 'ourselves',\n",
       " 'whatever',\n",
       " 'first',\n",
       " 'would',\n",
       " 'toward',\n",
       " 'yourself',\n",
       " 'there',\n",
       " 'me',\n",
       " 'now',\n",
       " 'eleven',\n",
       " 'twenty',\n",
       " 'please',\n",
       " 'therein',\n",
       " 'during',\n",
       " 'already',\n",
       " 'forty',\n",
       " 'hundred',\n",
       " 'n’t',\n",
       " 'somewhere',\n",
       " 'could',\n",
       " 'down',\n",
       " 'indeed',\n",
       " 'back',\n",
       " 'eight',\n",
       " 'he',\n",
       " 'say',\n",
       " 'both',\n",
       " 'once',\n",
       " 'seemed',\n",
       " '’m',\n",
       " 'see',\n",
       " 'be',\n",
       " 'whole',\n",
       " 'yet',\n",
       " 'unless',\n",
       " 'some',\n",
       " 'used',\n",
       " 'any',\n",
       " 'though',\n",
       " 'and',\n",
       " 'within',\n",
       " 'either',\n",
       " 'has',\n",
       " 'less',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'latter']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code to show list of usual word that has function but not meaning\n",
    "\n",
    "stopwords = list(STOP_WORDS)\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c184dd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make NLP model using en_core_web_sm\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d03bd0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cb20a5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'There', 'are', 'broadly', 'two', 'types', 'of', 'extractive', 'summarization', 'tasks', 'depending', 'on', 'what', 'the', 'summarization', 'the', 'first', 'is', 'generic', 'summarization', ',', 'which', 'focuses', 'on', 'obtaning', 'a', 'generic', 'summary', 'or', 'abstract', 'of', 'the', 'collection', '(', 'whethere', 'documments', ',', 'or', 'sets', 'of', 'images', ',', 'or', 'videos', ',', 'news', 'stories', 'stc', '.', ')', '.', 'The', 'second', 'is', 'query', 'relevant', 'summarizion', ',', 'sometimes', 'called', 'query', '-', 'based', 'summarizion', ',', 'which', 'summarizes', 'objects', 'specific', 'to', 'query', '.', 'Summarization', 'system', 'are', 'able', 'create', 'both', 'query', 'relevant', 'text', 'summarizes', 'and', 'generic', 'machine', '-', 'generated', 'summaries', 'depending', 'on', 'what', 'the', 'user', 'needs', '.', 'An', 'example', 'of', 'summarization', 'problem', 'is', 'document', 'summarization', 'wich', 'attempts', 'to', 'automatically', 'produce', 'an', 'abstract', 'from', 'a', 'given', 'document', '.', 'Sometimes', 'one', 'might', 'be', 'interested', 'in', 'generating', 'a', 'summary', 'from', 'a', 'single', 'source', 'document', ',', 'while', 'others', 'summarization', '.', 'A', 'related', 'application', 'is', 'summarizing', 'news', 'articles', '.', 'Imagine', 'a', 'system', ',', 'which', 'automatically', 'pulls', 'together', 'news', 'articles', 'on', 'a', 'given', 'topic', '(', 'from', 'the', 'web', ')', ',', 'and', 'concisely', 'represent', 'the', 'latest', 'news', 'as', 'a', 'summary', '.', 'Image', 'collection', 'summarization', 'is', 'another', 'application', 'example', 'of', 'automatic', 'summarization', '.', 'It', 'consists', 'in', 'selecting', 'a', 'representative', 'set', 'of', 'images', 'from', 'a', 'large', 'set', 'of', 'images', '.', 'A', 'summary', 'in', 'this', 'context', 'is', 'useful', 'to', 'show', 'the', 'most', 'representative', 'images', 'of', 'results', 'in', 'image', 'collection', 'exploration', 'system', '.', 'Video', 'summarization', 'is', 'a', 'related', 'domain', ',', 'where', 'one', 'the', 'iystem', 'automatically', 'creates', 'a', 'treailler', 'of', 'a', 'long', 'video', '.', 'this', 'aslo', 'has', 'application', 'in', 'consumer', 'or', 'personal', 'videos', ',', 'where', 'one', 'might', 'want', 'to', 'skip', 'the', 'boring', 'or', 'repetitive', 'actions', '.', 'Similarry', ',', 'in', 'surveillance', 'videos', ',', 'one', 'would', 'wnat', 'to', 'extract', 'important', 'and', 'suspicious', 'activity', ',', 'while', 'ignoring', 'all', 'the', 'boring', 'and', 'redundant', 'frames', 'captures', '.']\n"
     ]
    }
   ],
   "source": [
    "#show token list\n",
    "\n",
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6ab987e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\n\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add new row\n",
    "\n",
    "punctuation = punctuation + '\\n'\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54372651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show word frwuency\n",
    "\n",
    "word_frequencies = {}\n",
    "for word in doc:\n",
    "    if word.text.lower() not in stopwords:\n",
    "        if word.text.lower() not in punctuation:\n",
    "            if word.text not in word_frequencies.keys():\n",
    "                word_frequencies[word.text] = 1\n",
    "            else:\n",
    "                word_frequencies[word.text] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f8d5164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show max word frequecy\n",
    "\n",
    "max_frequency = max(word_frequencies.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67722739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e302ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalisation from each word in the text data\n",
    "\n",
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = word_frequencies[word]/max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ead7f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ , There are broadly two types of extractive summarization tasks depending on what the summarization the first is generic summarization, which focuses on obtaning a generic summary or abstract of the collection (whethere documments, or sets of images, or videos, news stories stc.)., The second is query relevant summarizion, sometimes called query-based summarizion, which summarizes objects specific to query., Summarization system are able create both query relevant text summarizes and generic machine-generated summaries depending on what the user needs., An example of summarization problem is document summarization wich attempts to automatically produce an abstract from a given document., Sometimes one might be interested in generating a summary from a single source document, while others summarization., A related application is summarizing news articles., Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represent the latest news as a summary., Image collection summarization is another application example of automatic summarization., It consists in selecting a representative set of images from a large set of images., A summary in this context is useful to show the most representative images of results in image collection exploration system., Video summarization is a related domain, where one the iystem automatically creates a treailler of a long video., this aslo has application in consumer or personal videos, where one might want to skip the boring or repetitive actions., Similarry, in surveillance videos, one would wnat to extract important and suspicious activity, while ignoring all the boring and redundant frames captures.]\n"
     ]
    }
   ],
   "source": [
    "#sentence tokenization\n",
    "\n",
    "sentence_tokens = [sent for sent in doc.sents]\n",
    "print(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8b2da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count sentence score\n",
    "\n",
    "sentence_scores = {}\n",
    "for sent in sentence_tokens:\n",
    "    for word in sent:\n",
    "        if word.text.lower() in word_frequencies.keys():\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent] += word_frequencies[word.text.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b4f2c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ : 0.1111111111111111,\n",
       " There are broadly two types of extractive summarization tasks depending on what the summarization the first is generic summarization, which focuses on obtaning a generic summary or abstract of the collection (whethere documments, or sets of images, or videos, news stories stc.).: 7.33333333333333,\n",
       " The second is query relevant summarizion, sometimes called query-based summarizion, which summarizes objects specific to query.: 2.7777777777777777,\n",
       " Summarization system are able create both query relevant text summarizes and generic machine-generated summaries depending on what the user needs.: 3.6666666666666674,\n",
       " An example of summarization problem is document summarization wich attempts to automatically produce an abstract from a given document.: 4.111111111111112,\n",
       " Sometimes one might be interested in generating a summary from a single source document, while others summarization.: 2.2222222222222223,\n",
       " A related application is summarizing news articles.: 1.3333333333333335,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represent the latest news as a summary.: 3.1111111111111116,\n",
       " Image collection summarization is another application example of automatic summarization.: 3.111111111111111,\n",
       " It consists in selecting a representative set of images from a large set of images.: 1.888888888888889,\n",
       " A summary in this context is useful to show the most representative images of results in image collection exploration system.: 2.3333333333333335,\n",
       " Video summarization is a related domain, where one the iystem automatically creates a treailler of a long video.: 2.3333333333333335,\n",
       " this aslo has application in consumer or personal videos, where one might want to skip the boring or repetitive actions.: 1.666666666666667,\n",
       " Similarry, in surveillance videos, one would wnat to extract important and suspicious activity, while ignoring all the boring and redundant frames captures.: 1.666666666666667}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c96f304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nlargest function\n",
    "\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e3e5156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count total word\n",
    "\n",
    "select_length = int(len(sentence_tokens)*0.3)\n",
    "select_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6f77b05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence summary  \n",
    "\n",
    "summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0fcffee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[There are broadly two types of extractive summarization tasks depending on what the summarization the first is generic summarization, which focuses on obtaning a generic summary or abstract of the collection (whethere documments, or sets of images, or videos, news stories stc.).,\n",
       " An example of summarization problem is document summarization wich attempts to automatically produce an abstract from a given document.,\n",
       " Summarization system are able create both query relevant text summarizes and generic machine-generated summaries depending on what the user needs.,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represent the latest news as a summary.]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e9609ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine sentences\n",
    "\n",
    "final_summary = [word.text for word in summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "369fb270",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = ' '.join(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a20aa45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are broadly two types of extractive summarization tasks depending on what the summarization the first is generic summarization, which focuses on obtaning a generic summary or abstract of the collection (whethere documments, or sets of images, or videos, news stories stc.). The second is query relevant summarizion, sometimes called query-based summarizion, which summarizes objects specific to query. Summarization system are able create both query relevant text summarizes and generic machine-generated summaries depending on what the user needs. An example of summarization problem is document summarization wich attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represent the latest news as a summary. Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a large set of images. A summary in this context is useful to show the most representative images of results in image collection exploration system. Video summarization is a related domain, where one the iystem automatically creates a treailler of a long video. this aslo has application in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarry, in surveillance videos, one would wnat to extract important and suspicious activity, while ignoring all the boring and redundant frames captures. \n"
     ]
    }
   ],
   "source": [
    "#print text\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e6d6fbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are broadly two types of extractive summarization tasks depending on what the summarization the first is generic summarization, which focuses on obtaning a generic summary or abstract of the collection (whethere documments, or sets of images, or videos, news stories stc.). An example of summarization problem is document summarization wich attempts to automatically produce an abstract from a given document. Summarization system are able create both query relevant text summarizes and generic machine-generated summaries depending on what the user needs. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represent the latest news as a summary.\n"
     ]
    }
   ],
   "source": [
    "#show the summary\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "41fbc6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are broadly two types of extractive summarization tasks depending on what the summarization the first is generic summarization, which focuses on obtaning a generic summary or abstract of the collection (whethere documments, or sets of images, or videos, news stories stc.). The second is query relevant summarizion, sometimes called query-based summarizion, which summarizes objects specific to query. Summarization system are able create both query relevant text summarizes and generic machine-generated summaries depending on what the user needs. An example of summarization problem is document summarization wich attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represent the latest news as a summary. Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a large set of images. A summary in this context is useful to show the most representative images of results in image collection exploration system. Video summarization is a related domain, where one the iystem automatically creates a treailler of a long video. this aslo has application in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarry, in surveillance videos, one would wnat to extract important and suspicious activity, while ignoring all the boring and redundant frames captures. \n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39775e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1706"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show text length\n",
    "\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "782f6601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "716"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show text after summary\n",
    "\n",
    "len(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d5a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
